\documentclass[a4paper]{scrartcl}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{rotating}

\title{The TTC 2019 Live Case:\\BibTeX to DocBook (v1.0)}
\author{
  Antonio García-Domínguez\\
  Aston University\\
  B4 7ET, Birmingham, United Kingdom\\
  a.garcia-dominguez@aston.ac.uk
}

\usepackage{tikz}
\usepackage{graphicx}
\graphicspath{{}{figures/}{../../metamodels/ttc2019.live.metamodels/models/}}

\usepackage[pdftex,colorlinks=true]{hyperref}

\usepackage{listings}
\lstset{columns=flexible}

\newcommand*{\class}[1]{\textsc{#1}}
\newcommand*{\feature}[1]{\emph{#1}}
\newcommand*{\file}[1]{\texttt{#1}}

\begin{document}

\maketitle

\begin{abstract}
  The initial transformation of a model into another model is only the first
  step. After the creation of the target model, it may be manually changed and
  the consistency with the source model may be lost or obscured. Ideally,
  transformation tools should have a way to check the degree of consistency
  between the source model and the current version of the destination model.
  This case presents such a scenario for a small transformation, with an
  automated mutation tool which will introduce changes that may or may not
  impact consistency. The aim of this case is to evaluate the speed and
  verbosity of the inter-model consistency checking in the state of the art.
\end{abstract}

\section{Introduction}

This live case is based on the original ATL Zoo~\cite{atlzoo} BibTeX to DocBook
transformation, where a simplified version of the BibTeX reference manager's
data model (shown in Figure~\ref{fig:bibtex-mm}) is transformed to a
simplification of the DocBook document typesetting tool (shown in
Figure~\ref{fig:docbook-mm}).

\begin{sidewaysfigure}
  \centering
  \includegraphics[width=\textheight]{bibtex}
  \caption{Class diagram for the input BibTeXML metamodel}
  \label{fig:bibtex-mm}
\end{sidewaysfigure}

\begin{figure}
  \centering
  \includegraphics[width=.7\textwidth]{docbook}
  \caption{Class diagram for the target DocBook metamodel}
  \label{fig:docbook-mm}
\end{figure}

The transformation is quite simple:

\begin{itemize}
\item From the root \class{BibTeXFile}, a \class{DocBook} is created. The
  \class{DocBook} has a \class{Book} with an \class{Article} titled ``BibTeXML
  to DocBook'', which has in turn four \class{Sect1} instances: ``References
  List'', ``Author List'', ``Titles List'' and ``Journals List''.

\item Any BibTeX \class{Author} is listed in the ``Authors List'' as a \class{Para}.

\item Any \class{BibTeX\-Entry} is listed in the ``References List'', including
  its unique identifier and any available information.

\item For each \class{Titled\-Entry}, a \class{Para} with its title is added to
  the ``Titles List''

\item For each BibTeX \class{Article}, a \class{Para} with its journal name is
  added to the ``Journals List''.

\item The ``Author List'', ``Titles List'', and ``Journals List'' are all sorted
  lexicographically in ascending order.
\end{itemize}

The transformation is somewhat different in that it involves some sorting. The
original ATL-based implementation worked well for instances with 10, 100 and
1000 entries, but seems to struggle with instances with 10000 entries.

Still, a more interesting problem is the case when the target model continues to
be worked on after the initial transformation. Suppose that we gave the DocBook
document to an editor, which would reorganise sections, add paragraphs in the
middle with further commentary and perhaps extend some of the text itself. The
task would be to ensure that these manual editions have not impacted the
consistency of the DocBook model with the original BibTeX model.

Ideally, the transformation tool or the editing environment would give some
infrastructure to tackle this. However, for many tools, the approach seems to be
only feasible through the creation of an external consistency checker. This case
is to evaluate the current state of the art in out-of-the-box after-the-fact
consistency checking. To do so, the case provides a generator which can produce
source models of arbitrary size, a repackaged version of the original ATL
transformation, and a mutator which can make a number of changes to the model,
some of which may impact consistency.

All resources for this case are available on
Github\footnote{\url{https://github.com/TransformationToolContest/ttc2019-live}}.
Please follow the link in the footnote and create a pull request with your own
solution.

The rest of the document is structured as follows:
Section~\ref{sec:case-structure} describes the structure of the live case.
Section~\ref{sec:task-description} describes the proposed tasks for this live
case. Section~\ref{sec:benchmark-framework} mentions the benchmark framework for
those solutions that focus on raw performance. Finally,
Section~\ref{sec:evaluation} mentions an outline of the initial audience-based
evaluation across all solutions, and the approach that will be followed to
derive additional prizes depending on the attributes targeted by the solutions.

\section{Case Structure}
\label{sec:case-structure}

The case is intended to review the different approaches for checking
after-the-fact inter-model consistency between a BibTeX model and a DocBook
model. The process is roughly as follows:

\begin{enumerate}
\item The BibTeX model is generated randomly to a certain size, by the included
  \emph{generator} in the \file{models/generator.jar} JAR. The generator uses a
  Java port of the Ruby Faker\footnote{\url{https://github.com/DiUS/java-faker}}
  library to produce random data.

  The generator is simple to use, if you wish to produce larger models:
\begin{verbatim}
java -jar generator.jar destination.bibtex size [seed]
\end{verbatim}

  \file{destination.bibtex} is the path to the file to be produced, and
  \file{size} is an integer with the number of desired entries. The random
  \file{seed} is an optional integer that will produce consistent results across
  reruns.

  A number of random models (sizes 10, 100, 1000 and 10000) have been produced
  already and are included in the case resources.

\item The BibTeX model is transformed automatically to DocBook by the repackaged
  version of the original ATL transformation in the \file{bibtex2docbook.jar}
  JAR. This transformation deals well with models up to 1000 entries, but seems
  to struggle with larger models. It can be used like this:
\begin{verbatim}
java -jar bibtex2docbook.jar in.bibtex out.docbook
\end{verbatim}

\item The DocBook model is edited, in this case with the automated
  \emph{mutator} in the \file{models/mutator.jar} JAR. It can be invoked with
  the following command:
\begin{verbatim}
java -jar mutator.jar source.docbook \
  dirPrefix nMutants [nMutationsPerMutant=1] [seed=time]
\end{verbatim}

\begin{sidewaysfigure}
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{changes}
  \caption{Class diagram for the Changes metamodel}
  \label{fig:changes-mm}
\end{sidewaysfigure}

The mutator will operate on a DocBook file, creating a set of folders whose path
will start with the specified prefix, adding \file{-N} from 1 to
\file{nMutants}. Each folder will contain the mutated DocBook model, as well as
a \emph{change model} explaining what was done to the model:
Figure~\ref{fig:changes-mm} shows that such models have a \class{ModelChangeSet}
as the root, with a number of \class{Model\-Change} instances of various types.
The DocBook model will have gone through a number of random mutations according
to a seed: if unspecified, the seed will be based on the current system time.

The mutator has a number of predefined \emph{mutation operators} that will
modify the model:

\begin{itemize}
\item Swapping paragraphs: this should break consistency in terms of sorting,
  but it will not result in missing information.
\item Swapping sections should not break consistency.
\item Deleting paragraphs/sections should break consistency.
\item Appending text to a paragraph should not break consistency.
\item Adding a new paragraph: unless it happens to match one of the authors,
  titles, or journals in its \class{Sect1}, it should not break consistency.
\end{itemize}

The mutated models have been created already. There are three sets of mutated
models from the generated 10/100-entry models: one with a single mutation, one
with two mutations, and one with three mutations.

\item A \emph{consistency checker} would take any combination of the previous
  artifacts (source BibTeX, fresh DocBook, mutated DocBook, change model) and
  make a judgment about whether the mutated DocBook is still consistent or not.

  If issues are found, it should point to the element in the source model which
  lacks a proper mapping on the other side, or the element in the target model
  which is not mapped correctly from the source model (e.g. it is not sorted
  anymore).
\end{enumerate}

\section{Task Description}
\label{sec:task-description}

There is an optional task and a mandatory task in this case:

\begin{itemize}
\item The optional task is to re-implement or improve the original
  transformation itself, in a way that lends itself better to after-the-fact
  consistency checking. Your transformation tool may have better support for
  this, or ATL could be made to deal better with larger versions of this model.

\item The mandatory task is to check for the consistency of the source BibTeX
  against the mutated DocBook models in the \file{models} directory, and report
  this information as efficiently and clearly as possible to the user. To
  evaluate the efficiency of your approach, you must use the benchmarking
  framework further detailed in Section~\ref{sec:benchmark-framework}. Ideally,
  this should be possible without a full re-run of the transformation.
\end{itemize}

Solutions can focus on efficiency, conciseness, or clarity of presentation to
the user. Solutions that can operate straight from the definition of the
transformation (i.e.\ without a separate consistency checker) would be preferred.

\section{Benchmark Framework}
\label{sec:benchmark-framework}

If focusing on performance, the solution authors should integrate their solution
with the provided benchmark framework. It is based on that of the TTC 2017 Smart
Grid case~\cite{hinkel_ttc_2017}, and supports the automated build and execution
of solutions. For this specific case study, the visualisation of the results is
currently disabled.

The benchmark consists of three phases:

\begin{enumerate}
\item \textbf{Initialization}, which involves setting up the basic
  infrastructure (e.g. loading metamodels). These measurements are optional.
\item \textbf{Load}, which loads the input models.
\item \textbf{Run}, which runs the consistency checking, finding a number of
  consistency violations in the mutated DocBook model.
\end{enumerate}

\subsection{Solution requirements}
\label{sec:solut-requ}

Solutions should be forks of the main Github
project\footnote{\url{https://github.com/TransformationToolContest/ttc2019-live}},
and should be submitted as pull requests.

Each solution wishing to use the benchmarking framework should print to the
standard output a line with the following fields, separated by semicolons
(``;''):

\begin{itemize}
\item \textbf{Tool}: name of the tool.
\item \textbf{MutantSet}: set of mutants used (``single'', ``double'' or ``triple'').
\item \textbf{Source}: base name of the input BibTeX model (e.g.\ ``random10.bibtex'').
\item \textbf{Mutant}: integer starting at 1, identifying the mutant model within this set.
\item \textbf{RunIndex}: index of the run of this combination of tools and inputs.
\item \textbf{PhaseName}: name of the phase being run.
\item \textbf{MetricName}: the name of the metric. It may be the used
  \textbf{Memory} in bytes, the wall clock \textbf{Time} spent in integer
  nanoseconds, or the number of consistency \textbf{Problems} found in the
  mutated DocBook model.
\end{itemize}

\lstinputlisting[
  float,frame=tb,numbers=left,
  caption={\file{solution.ini} file for the reference Epsilon solution},
  label=lst:ini-atl
]{../../solutions/Epsilon/solution.ini}

To enable automatic execution by the benchmark framework, solutions should add a
subdirectory to the \file{solutions} folder of the benchmark with a
\file{solution.ini} file stating how the solution should be built and how it
should be run. As an example, the \file{solution.ini} file for the reference
solution is shown on Listing~\ref{lst:ini-atl}. In the \file{build} section, the
\file{default} option specifies the command to build and test the solution, and
the \file{skipTests} option specifies the command to build the solution while
skipping unit tests. In the \file{run} section, the \file{cmd} option specifies
the command to run the solution.

The repetition of executions as defined in the benchmark configuration is done
by the benchmark. For 5 runs, the specified command will be called 5 times,
passing any required information (e.g. run index, or input model name) through
environment variables. Solutions must not save intermediate data between
different runs: each run should be entirely independent.

The name and absolute path of the input model, the run index and the name of the
tool are passed using environment variables \file{Tool}, \file{MutantSet},
\file{SourcePath}, \file{Mutant}, \file{MutantPath}, and \file{RunIndex}.
Solution authors are suggested to study the reference solution on how to use
these values to run their transformation.

\subsection{Running the benchmark}
\label{sec:running-benchmark}

The benchmark framework only requires Python 3.3 to be installed. Furthermore,
the solutions may imply additional frameworks. We would ask solution authors to
explicitly note dependencies to additional frameworks necessary to run their
solutions.

If all prerequisites are fulfilled, the benchmark can be run using Python with
the command \file{python scripts/run.py}. Additional options can be queried
using the option \file{{-}{-}help}. The benchmark framework can be configured
through the \file{config/config.json} file: this includes the input models to be
evaluated (some of which have been excluded by default due to their high cost
with the sample solution), the names of the tools to be run, the number of runs
per tool+model, and the timeout for each command in milliseconds.

\section{Evaluation}
\label{sec:evaluation}

The evaluation will operate on several dimensions:

\begin{itemize}
\item How efficient is the approach in time and space (memory)? The reference
  ATL solution struggled with large models, and the reference solution has not
  been designed with performance in mind.

\item Is consistency checking directly supported by the transformation approach?
  Many tools lack this capability, though it might be interesting as an
  additional execution mode if the target model has seen manual changes since it
  was generated.

\item How informative and accessible is the feedback that can be provided by the
  approach?
\end{itemize}

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}
